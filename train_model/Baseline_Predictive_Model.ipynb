{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pharmaceutical-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_exploration_tools as EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-williams",
   "metadata": {},
   "source": [
    "Import the most recent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "macro-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = dt.today().day\n",
    "month = dt.today().month\n",
    "year = dt.today().year\n",
    "\n",
    "dt_str = os.path.join('.', 'reddit_data_{}-{}-{}'.format(month, day, year) )\n",
    "\n",
    "df = pd.read_pickle(dt_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-gather",
   "metadata": {},
   "source": [
    "Clean up the data by building a few new simple features, dropping useless columns (including those which have a cardinality of 1), and dropping all instances of Subreddits which aren't useful to the endeavor (e.g. '\\r\\blog' which only has two posts, both of which are gilded, and is a subreddit entirely devoted to Moderator posts about the Reddit platform itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aware-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = ['gilded', 'weekday', 'post_hour', 'scrape_time']\n",
    "new_cols = EDA.handle_unique_columns(df)\n",
    "\n",
    "for idx, feature in enumerate(new_feats):\n",
    "    df[feature] = new_cols[idx]\n",
    "\n",
    "df.drop(columns = EDA.get_all_useless_cols(df), inplace = True)\n",
    "df = EDA.remove_useless_subreddits(df, ['blog']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-residence",
   "metadata": {},
   "source": [
    "## Build a simple model using heuristics\n",
    "\n",
    "Rather than trying to throw some Machine Learning algorithms at the problem right off the bat, I will try to build a very simple probabilistic model based on a few of the features. This will give a baseline, a more complicated model must show significant improvement over this one if it is to be considered succesfull. \n",
    "\n",
    "Three features stand out as having good predictive power:\n",
    "\n",
    "* *Subreddit*\n",
    "* *Post Hour*\n",
    "* *Upvote Rate*\n",
    "\n",
    "For the discrete, categorical variables *Subreddit* and *Post Hour* I will use the relative frequency of gilded posts in each bin to define a probability-of-gilding to use for predictions. For *Upvote Rate* I will first need to bin before also calculating the relative frequency.\n",
    "\n",
    "Be iterating over every possible combination of values within these three features the relative frequencies will be computed *without* assuming that the features are independent of one another. The price paid for this is a relatively resource-expensive calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-patch",
   "metadata": {},
   "source": [
    "#### Binning\n",
    "\n",
    "Need a tool for binning across multiple features and computing quantities of interest for each bin. This iterates over every combination, a very brute-force approach that relies on both Pandas and Numpy. A vectorized treatment would be preferable - however as this is likely a one-time-use tool there does not seem to be a strong argument made for spending more time improving efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atmospheric-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "class target_fraction_in_bin:\n",
    "    '''Bin two or more features and calculate relative frequency of the target variable'''\n",
    "    \n",
    "    def __init__(self, df, feature_names, target_name, target_value = 1, sort = None):\n",
    "        \n",
    "        self.df = df\n",
    "        self.target_name = target_name\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "        self.sort_dict = self.build_sort_dict(sort)\n",
    "        \n",
    "        self.unique_values_dict = self.build_unique_values_dict()\n",
    "        self.dimensions = [self.unique_entries(feature) for feature in feature_names]\n",
    "        self.target_mask = (df[target_name] == target_value)\n",
    "        \n",
    "        self.totals_array, self.targets_array, self.fractions_array = self.build_arrays()\n",
    "    \n",
    "    \n",
    "    def build_sort_dict(self, sort):\n",
    "        \n",
    "        sort_dict = {}\n",
    "        for feat in self.feature_names:\n",
    "            try:\n",
    "                sort_dict[feat] = sort[feat]\n",
    "            except (KeyError, TypeError):\n",
    "                sort_dict[feat] = False \n",
    "        \n",
    "        return sort_dict\n",
    "    \n",
    "        \n",
    "    def build_unique_values_dict(self):\n",
    "       \n",
    "        unique_vals = {}\n",
    "        for feature in self.feature_names:\n",
    "            if self.sort_dict[feature]:\n",
    "                counts = self.df.groupby(feature).count().iloc[:,0]\n",
    "                sorted_counts = counts.sort_values(ascending = False)\n",
    "                unique_vals[feature] = list(sorted_counts.index)\n",
    "            else:\n",
    "                unique_vals[feature] = self.df[feature].unique()\n",
    "        return unique_vals\n",
    "    \n",
    "          \n",
    "    def build_boolean_mask(self, idx):\n",
    "        \n",
    "        N = self.df.shape[0]\n",
    "        mask = pd.Series([True]*N)\n",
    "        for feat_idx, val_idx in enumerate(idx):\n",
    "            feat_name = self.feature_names[feat_idx]\n",
    "            value = self.unique_values_dict[feat_name][val_idx]\n",
    "            feature_mask = self.df[feat_name] == value\n",
    "            mask &= feature_mask\n",
    "            \n",
    "        return mask\n",
    "    \n",
    "            \n",
    "    def build_arrays(self):\n",
    "        # Initialize all arrays\n",
    "        totals_array = np.zeros(self.dimensions)\n",
    "        targets_array = np.zeros(self.dimensions)\n",
    "        fractions_array = np.zeros(self.dimensions)\n",
    "        \n",
    "        for idx, _ in np.ndenumerate(totals_array):\n",
    "            # Build masks\n",
    "            values_mask = self.build_boolean_mask(idx)\n",
    "            target_values_mask = (self.target_mask & values_mask)\n",
    "            \n",
    "            # Use masks to count\n",
    "            totals_array[idx] = values_mask.sum()\n",
    "            targets_array[idx] = target_values_mask.sum()\n",
    "            \n",
    "            # Calculate fractions from counts\n",
    "            if totals_array[idx] == 0:\n",
    "                fractions_array[idx] = 0\n",
    "            else:\n",
    "                fractions_array[idx] = targets_array[idx]/totals_array[idx]\n",
    "\n",
    "        \n",
    "        return totals_array, targets_array, fractions_array\n",
    "    \n",
    "\n",
    "\n",
    "    def unique_entries(self, feature_name):\n",
    "        return len(self.df[feature_name].unique())\n",
    "\n",
    "\n",
    "    def fraction(self):\n",
    "        return self.fractions_array\n",
    "    \n",
    "    \n",
    "    def num_target(self):\n",
    "        return self.targets_array\n",
    "    \n",
    "    \n",
    "    def num_in_bin(self):\n",
    "        return self.totals_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-lottery",
   "metadata": {},
   "source": [
    "#### Prep the features\n",
    "Need to bin *upvote_rate* so it can be included in the analysis. Will store the three prepared features in a separate dataframe (with the *gildings* column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broken-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histedges_equalN(x, num_bins):\n",
    "    num_pts = len(x)\n",
    "    bins = np.interp(np.linspace(0, num_pts, num_bins + 1),\n",
    "                     np.arange(num_pts),\n",
    "                     np.sort(x)\n",
    "                    )\n",
    "    return bins\n",
    "\n",
    "upvote_rate_bins = histedges_equalN(df['upvote_rate'], 10)\n",
    "\n",
    "upvote_rate_bin_nums = pd.Series(np.zeros(df.shape[0]))\n",
    "rate_middles = {}\n",
    "for j, lower_bound in enumerate(upvote_rate_bins[:-1]):\n",
    "    upper_bound = upvote_rate_bins[j+1]\n",
    "    middle = (upper_bound + lower_bound)/2\n",
    "    \n",
    "    bool_mask = (df['upvote_rate'] >= lower_bound) & (df['upvote_rate'] < upper_bound)\n",
    "    upvote_rate_bin_nums += bool_mask.astype(int)*j\n",
    "    \n",
    "    rate_middles[j] = middle\n",
    "    \n",
    "    \n",
    "data = df.copy()[['subreddit', 'post_hour', 'gilded']]\n",
    "data['up_rate_bins'] = upvote_rate_bin_nums.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-external",
   "metadata": {},
   "source": [
    "#### Look at results of binning\n",
    "\n",
    "After binning the data heatmaps will show the results - will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data = target_fraction_in_bin(df = data,\n",
    "                                  feature_names = ['subreddit', 'post_hour', 'up_rate_bins'],\n",
    "                                  target_name = 'gilded',\n",
    "                                  sort = {'subreddit':True, 'up_rate_bins':True}\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-supplement",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "def get_nonzero_min(A):\n",
    "    all_nums = []\n",
    "    for _, number in np.ndenumerate(A):\n",
    "        if number > 0:\n",
    "            all_nums.append(number)\n",
    "    return min(all_nums)\n",
    "\n",
    "subs = bin_data.unique_values_dict['subreddit']\n",
    "hours = bin_data.unique_values_dict['post_hour']\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize = (25,35))\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "\n",
    "\n",
    "totals = np.transpose(np.sum(bin_data.num_in_bin(),2))\n",
    "totals_hmap = ax1.imshow(totals, cmap = 'BuPu', norm=LogNorm(vmin=1, vmax = totals.max()))\n",
    "ax1.set_xticks(range(len(subs)))\n",
    "ax1.set_xticklabels(subs, rotation = 90)\n",
    "ax1.set_title('All Posts', fontsize = 18)\n",
    "ax1.set_ylabel('Hour of the Day', fontsize = 14)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(totals_hmap, cax = cax)\n",
    "\n",
    "gilded = np.transpose(np.sum(bin_data.num_target(),2))\n",
    "gilded_hmap = ax2.imshow(gilded, cmap = 'BuPu', norm=LogNorm(vmin=1, vmax = gilded.max()))\n",
    "ax2.set_xticks(range(len(subs)))\n",
    "ax2.set_xticklabels(subs, rotation = 90)\n",
    "ax2.set_title('All Gilded Posts', fontsize = 18)\n",
    "ax2.set_ylabel('Hour of the Day', fontsize = 14)\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(gilded_hmap, cax = cax)\n",
    "\n",
    "\n",
    "fractions = np.transpose(np.sum(bin_data.fraction(),2))\n",
    "fracs_hmap = ax3.imshow(fractions, cmap = 'BuPu', norm=LogNorm(vmin=get_nonzero_min(fractions), vmax = fractions.max()))\n",
    "ax3.set_xticks(range(len(subs)))\n",
    "ax3.set_xticklabels(subs, rotation = 90)\n",
    "ax3.set_title('Fraction of Posts Gilded', fontsize = 18)\n",
    "ax3.set_ylabel('Hour of the Day', fontsize = 14)\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(fracs_hmap, cax = cax)\n",
    "\n",
    "#fig.set_size_inches(60, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "subs = bin_data.unique_values_dict['subreddit']\n",
    "up_rates_bin_nums = bin_data.unique_values_dict['up_rate_bins']\n",
    "up_rates = [round(rate_middles[num],2) for num in up_rates_bin_nums]\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1)#, figsize = (25,35))\n",
    "plt.subplots_adjust(hspace = 0.8)\n",
    "\n",
    "totals = np.transpose(np.sum(bin_data.num_in_bin(),1))\n",
    "totals_hmap = ax1.imshow(totals, cmap = 'BuPu', norm=LogNorm(vmin=1, vmax = totals.max()))\n",
    "\n",
    "ax1.set_xticks(range(len(subs)))\n",
    "ax1.set_xticklabels(subs, rotation = 90)\n",
    "ax1.set_yticks(range(len(up_rates)))\n",
    "ax1.set_yticklabels(up_rates)\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_title('All Posts', fontsize = 18)\n",
    "ax1.set_ylabel('Upvote Rate', fontsize = 14)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(totals_hmap, cax = cax)\n",
    "\n",
    "gilded = np.transpose(np.sum(bin_data.num_target(),1))\n",
    "gilded_hmap = ax2.imshow(gilded, cmap = 'BuPu', norm=LogNorm(vmin=1, vmax = gilded.max()))\n",
    "ax2.set_xticks(range(len(subs)))\n",
    "ax2.set_xticklabels(subs, rotation = 90)\n",
    "ax2.set_yticks(range(len(up_rates)))\n",
    "ax2.set_yticklabels(up_rates)\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_title('All Gilded Posts', fontsize = 18)\n",
    "ax2.set_ylabel('Upvote Rate', fontsize = 14)\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(gilded_hmap, cax = cax)\n",
    "\n",
    "\n",
    "fractions = np.transpose(np.sum(bin_data.fraction(),1))\n",
    "fracs_hmap = ax3.imshow(fractions, cmap = 'BuPu', norm=LogNorm(vmin=get_nonzero_min(fractions), vmax = fractions.max()))\n",
    "ax3.set_xticks(range(len(subs)))\n",
    "ax3.set_xticklabels(subs, rotation = 90)\n",
    "ax3.set_yticks(range(len(up_rates)))\n",
    "ax3.set_yticklabels(up_rates)\n",
    "ax3.invert_yaxis()\n",
    "ax3.set_title('Fraction of Posts Gilded', fontsize = 18)\n",
    "ax3.set_ylabel('Upvote Rate', fontsize = 14)\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(fracs_hmap, cax = cax)\n",
    "\n",
    "fig.set_size_inches(60, 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "#subs = bin_data.unique_values_dict['subreddit']\n",
    "up_rates_bin_nums = bin_data.unique_values_dict['up_rate_bins']\n",
    "up_rates = [round(rate_middles[num],2) for num in up_rates_bin_nums]\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize = (25,25))\n",
    "plt.subplots_adjust(hspace = 0.2)\n",
    "\n",
    "totals = np.transpose(np.sum(bin_data.num_in_bin(),0))\n",
    "totals_hmap = ax1.imshow(totals, cmap = 'BuPu', norm=LogNorm(vmin=1, vmax = totals.max()))\n",
    "\n",
    "ax1.set_xlabel('Hour of the Day Posted(utc)')\n",
    "ax1.set_yticks(range(len(up_rates)))\n",
    "ax1.set_yticklabels(up_rates)\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_title('All Posts', fontsize = 18)\n",
    "ax1.set_ylabel('Upvote Rate', fontsize = 14)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(totals_hmap, cax = cax)\n",
    "\n",
    "gilded = np.transpose(np.sum(bin_data.num_target(),0))\n",
    "gilded_hmap = ax2.imshow(gilded, cmap = 'BuPu', norm=LogNorm(vmin=1, vmax = gilded.max()))\n",
    "ax2.set_xlabel('Hour of the Day Posted(utc)')\n",
    "ax2.set_yticks(range(len(up_rates)))\n",
    "ax2.set_yticklabels(up_rates)\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_title('All Gilded Posts', fontsize = 18)\n",
    "ax2.set_ylabel('Upvote Rate', fontsize = 14)\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(gilded_hmap, cax = cax)\n",
    "\n",
    "\n",
    "fractions = np.transpose(np.sum(bin_data.fraction(),0))\n",
    "fracs_hmap = ax3.imshow(fractions, cmap = 'BuPu', norm=LogNorm(vmin=get_nonzero_min(fractions), vmax = fractions.max()))\n",
    "ax3.set_xlabel('Hour of the Day Posted(utc)')\n",
    "ax3.set_yticks(range(len(up_rates)))\n",
    "ax3.set_yticklabels(up_rates)\n",
    "ax3.invert_yaxis()\n",
    "ax3.set_title('Fraction of Posts Gilded', fontsize = 18)\n",
    "ax3.set_ylabel('Upvote Rate', fontsize = 14)\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.15)\n",
    "plt.colorbar(fracs_hmap, cax = cax)\n",
    "\n",
    "#fig.set_size_inches(20, 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-surrey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "declared-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator \n",
    "from sklearn.base import RegressorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "approximate-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoricalEstimator(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, normalization_constant = 1):\n",
    "        \"\"\"\n",
    "        Import all binning data and set a normalization constant to uniformly modify all fractions.\n",
    "        \"\"\"\n",
    "        self.normalization_constant = normalization_constant\n",
    "        \n",
    "\n",
    "    def fit(self, X, Y=None):\n",
    "        \"\"\"\n",
    "        Fit global model on X features to minimize \n",
    "        a given function on Y.\n",
    "\n",
    "        @param X\n",
    "        @param Y\n",
    "        \"\"\"\n",
    "        bin_data = target_fraction_in_bin(df = X,\n",
    "                                          feature_names = ['subreddit', 'post_hour', 'up_rate_bins'],\n",
    "                                          target_name = 'gilded',\n",
    "                                          sort = {'subreddit':True, 'up_rate_bins':True}\n",
    "                                         )\n",
    "        self.fractions = bin_data.fraction()\n",
    "        self.subreddits = bin_data.unique_values_dict['subreddit']\n",
    "        self.post_hours = bin_data.unique_values_dict['post_hour']\n",
    "        self.up_rate_bins = bin_data.unique_values_dict['up_rate_bins']\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    \n",
    "    def value_to_idx(self,x):\n",
    "        \n",
    "        sub_idx = list(self.subreddits).index(x['subreddit'])\n",
    "        time_idx = list(self.post_hours).index(x['post_hour'])\n",
    "        uprate_idx = list(self.up_rate_bins).index(x['up_rate_bins'])\n",
    "        \n",
    "        return (sub_idx, time_idx, uprate_idx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, X, normalalization=1):\n",
    "        \"\"\"\n",
    "        @param X: features vector the model will be evaluated on\n",
    "        \"\"\"\n",
    "        self.predicted_fracs = X.apply(lambda x: self.fractions[self.value_to_idx(x)], axis = 1)*normalalization\n",
    "        \n",
    "        #thresh = 0.5\n",
    "        #predictions = predicted_fracs.map(lambda x: 1 if x > thresh else 0)\n",
    "        predictions = self.predicted_fracs.map(lambda x: np.random.binomial(1,x,1)[0])\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "impressed-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "local-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "civilian-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HistoricalEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "willing-nowhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistoricalEstimator()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "sustainable-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(data_test, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "adjusted-eugene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26828    0\n",
       "1255     0\n",
       "57935    0\n",
       "49265    0\n",
       "31642    0\n",
       "        ..\n",
       "58818    0\n",
       "28806    0\n",
       "78549    0\n",
       "8314     0\n",
       "47893    0\n",
       "Length: 63448, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "soviet-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "conditional-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0449438202247191"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(data_test['gilded'], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "available-sigma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011922503725782414"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(data_test['gilded'], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "operational-ambassador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028054469802042616"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.sum()/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "annual-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clf.predicted_fracs)\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-screening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-treasure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
