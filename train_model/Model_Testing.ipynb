{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.pipeline import Pipeline as skl_Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "\n",
    "from pipeline_objects import PrepData, MyTargetEncoder, MultipurposeEncoder, make_evaluation_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = dt.today().day\n",
    "month = dt.today().month\n",
    "year = dt.today().year\n",
    "\n",
    "dt_str = os.path.join('.', 'reddit_data_{}-{}-{}'.format(month, day, year) )\n",
    "\n",
    "df_orig = pd.read_pickle(dt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_enc_feats = ['contest_mode', 'edited', 'adult_content', 'oc', 'reddit_media', 'selfpost',\n",
    "             'video', 'distinguished',\n",
    "            ]\n",
    "target_enc_feats = ['content_categories', 'subreddit', 'weekday', 'post_hour']\n",
    "\n",
    "drop_feats = ['final_upvotes', 'final_num_comments', 'title', 'how_sorted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = PrepData(drop_feats = drop_feats)\n",
    "df_prepped = data_prep.fit_transform(df_orig)\n",
    "\n",
    "X = df_prepped.drop(columns = 'gilded')\n",
    "y = df_prepped['gilded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-amplifier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = DummyClassifier(strategy = 'stratified')\n",
    "dum.fit(X_train, y_train)\n",
    "\n",
    "dum_predictions = dum.predict(X_test)\n",
    "\n",
    "dum_prec = precision_score(y_test, dum_predictions)\n",
    "dum_reca = recall_score(y_test, dum_predictions)\n",
    "\n",
    "print('Precision is: {:.1f}%'.format(dum_prec*100))\n",
    "print('Recall is: {:.1f}%'.format(dum_reca*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-aside",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-military",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "current_ratio = y_train.sum()/(~y_train).sum()\n",
    "\n",
    "xgb = XGBClassifier(eval_metric = 'aucpr', use_label_encoder = False, verbosity = 0 )\n",
    "\n",
    "#rmf = RandomForestClassifier(n_jobs = -1)\n",
    "over = SMOTE()\n",
    "under = RandomUnderSampler()\n",
    "\n",
    "\n",
    "resample_pipe = imb_Pipeline([('over', over),\n",
    "                              ('under', under),\n",
    "                              ('model', xgb)\n",
    "                             ])\n",
    "\n",
    "pipe = skl_Pipeline([('categ_enc', MultipurposeEncoder(ohe_feats = ohe_enc_feats, \n",
    "                                                       target_feats = target_enc_feats,\n",
    "                                                       target_how = 'additive_smoothing',\n",
    "                                                      )),\n",
    "                     ('scaler', StandardScaler()),\n",
    "                     #('decomp', PCA()),\n",
    "                     ('resample_classify', resample_pipe)\n",
    "                    ])\n",
    "\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "parameters = {'resample_classify__model__eta':[0.25],\n",
    "              'resample_classify__model__gamma':[2],\n",
    "              'resample_classify__model__min_child_weight':[5],              \n",
    "              'resample_classify__model__max_depth': [3],\n",
    "              'resample_classify__model__max_delta_step': [10],\n",
    "              'resample_classify__model__subsample': [1],\n",
    "              'resample_classify__model__sampling_method': ['uniform'],\n",
    "              'resample_classify__model__lambda': [10],\n",
    "              'resample_classify__model__alpha': [0],\n",
    "              'resample_classify__model__scale_pos_weight': [2],              \n",
    "              'resample_classify__over__sampling_strategy': [current_ratio*1.01],\n",
    "              'resample_classify__under__sampling_strategy': [current_ratio*1.01],              \n",
    "              'categ_enc__target_weight': [0], \n",
    "             # 'decomp__n_components': [0.99]\n",
    "             }\n",
    "\n",
    "\n",
    "clf = GridSearchCV(pipe,\n",
    "                   parameters,\n",
    "                   n_jobs = -1,\n",
    "                   #scoring = pr_auc_scorer,\n",
    "                   scoring = 'average_precision',\n",
    "                   verbose = 1,\n",
    "                  )\n",
    "_ = clf.fit(X_train, y_train)\n",
    "\n",
    "thresh = 0.10\n",
    "make_evaluation_plots(clf, X_train, y_train, X_test, y_test, thresh = thresh)\n",
    "\n",
    "cv_fits = pd.DataFrame(clf.cv_results_)\n",
    "cv_fits.iloc[:,-8:].sort_values('rank_test_score', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = clf.best_estimator_['resample_classify']['model'].feature_importances_\n",
    "pd.Series(feat_imp, index = X_train.columns).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-holly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-mileage",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([1,4,5,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.name = 'poop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-drove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-vision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-breast",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probas = [x[1] for x in clf.predict_proba(X_test)] \n",
    "predictions = [True if x > thresh else False for x in probas]\n",
    "\n",
    "outcomes = pd.DataFrame({'gilded': y_test, 'predicted': predictions, 'probas': probas})\n",
    "pos_outcomes = outcomes[ outcomes['predicted'] == True]\n",
    "neg_outcomes = outcomes[ outcomes['predicted'] == False]\n",
    "\n",
    "predicted_positive = (pos_outcomes\n",
    "                      .groupby([pd.cut(pos_outcomes['probas'], bins=10)])\n",
    "                      .sum()\n",
    "                      .iloc[:,:-1]\n",
    "                      .reset_index()\n",
    "                     )\n",
    "predicted_positive['center'] = predicted_positive['probas'].apply(lambda x: (x.left + x.right)/2)\n",
    "predicted_positive['false pos'] = predicted_positive['predicted'] - predicted_positive['gilded']\n",
    "\n",
    "predicted_negative = (neg_outcomes\n",
    "                      .groupby([pd.cut(neg_outcomes['probas'], bins=10)])\n",
    "                      .agg(['count', 'sum'])\n",
    "                      .iloc[:,:2]\n",
    "                      .reset_index()\n",
    "                     )\n",
    "predicted_negative['center'] = predicted_negative['probas'].apply(lambda x: (x.left + x.right)/2)\n",
    "predicted_negative['true neg'] = predicted_negative[('gilded', 'count')] - predicted_negative[('gilded', 'sum')]\n",
    "predicted_negative['false neg'] = predicted_negative[('gilded', 'sum')]\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (15,5))\n",
    "ax1.bar(predicted_positive['center'],\n",
    "       predicted_positive['gilded'],\n",
    "       width=0.02,\n",
    "       color = 'blue',\n",
    "       alpha = 0.7,\n",
    "       label = 'True positives'\n",
    "      )\n",
    "ax1.bar(predicted_positive['center'],\n",
    "       predicted_positive['false pos'], \n",
    "       bottom = predicted_positive['gilded'],\n",
    "       width=0.02,\n",
    "       color = 'red',\n",
    "       alpha = 0.7,\n",
    "       label = 'False positives'\n",
    "      )\n",
    "ax1.set_xticks(predicted_positive['center'])\n",
    "ax1.set_xticklabels([round(x,2) for x in predicted_positive['center']])\n",
    "ax1.legend(loc = 'upper right')\n",
    "ax1.set_title('Predict: Gilded')\n",
    "ax1.set_xlabel('Predicted Probability of Gilding')\n",
    "\n",
    "ax2.bar(predicted_negative['center'],\n",
    "       predicted_negative['true neg'],\n",
    "       width=0.007,\n",
    "       color = 'blue',\n",
    "       alpha = 0.7,\n",
    "       label = 'True negatives'\n",
    "      )\n",
    "ax2.bar(predicted_negative['center'],\n",
    "       predicted_negative['false neg'], \n",
    "       bottom = predicted_negative['true neg'],\n",
    "       width=0.007,\n",
    "       color = 'red',\n",
    "       alpha = 0.7,\n",
    "       label = 'False negatives'\n",
    "      )\n",
    "ax2.set_xticks(predicted_negative['center'])\n",
    "ax2.set_xticklabels([round(x,2) for x in predicted_negative['center']])\n",
    "ax2.legend(loc = 'upper right')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('Predict: Not Gilded')\n",
    "ax2.set_xlabel('Predicted Probability of Gilding')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-texas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-nerve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-cambridge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-duplicate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-insurance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-library",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-siemens",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reddit",
   "language": "python",
   "name": "reddit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
