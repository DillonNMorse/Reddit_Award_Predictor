{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pprint\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.0.0 of praw is outdated. Version 7.1.0 was released Tuesday June 23, 2020.\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id = 'h8BBe0NNslxi8g', \n",
    "                     client_secret = 'gd2EfD_bd9njZI9zngbiD1WhMJo8lA', \n",
    "                     user_agent = 'Chrome:AwardPredictor:v0.0.1 (by /u/drdnm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aww = reddit.subreddit('aww')\n",
    "hist = reddit.subreddit('history')\n",
    "askred = reddit.subreddit('askreddit')\n",
    "\n",
    "multi = reddit.subreddit('aww+history+askreddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_hot = multi.hot(limit = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toplevel_comment_info(subm, num_top_comments = 5):\n",
    "    \n",
    "    # 'num_top_level' controls the number of highest-upvoted top-level comments for which the replies will be counted\n",
    "    \n",
    "    t_del_1 = datetime.datetime.now()\n",
    "    \n",
    "    \n",
    "    # Delete all \"more comments\" entries to avoid errors - puts a cap on max number of comments retrieved\n",
    "    subm.comments.replace_more(limit = 0) \n",
    "    \n",
    "    \n",
    "    t_del_2 = datetime.datetime.now()\n",
    "    t_del = (t_del_2 - t_del_1).total_seconds()\n",
    "    \n",
    "    \n",
    "\n",
    "    # List of features of interest to pull from the API\n",
    "    api_feat = {'Gilded': 'gilded',\n",
    "                'Gildings': 'gildings',\n",
    "                'Upvotes': 'ups',\n",
    "                'Downvotes': 'downs',\n",
    "                'Distinguished': 'distinguished',\n",
    "                'Edited': 'edited',\n",
    "                'Controversiality': 'controversiality',\n",
    "                'OP comment': 'is_submitter'\n",
    "               }\n",
    "    \n",
    "    \n",
    "    \n",
    "    t_feat_1 = datetime.datetime.now()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Iterate through all comments to extract their features\n",
    "    max_number_of_comments = 3*num_top_comments\n",
    "    comment_features = {}\n",
    "    for comment_number, comment in enumerate(subm.comments):\n",
    "        if comment_number > max_number_of_comments:\n",
    "            break\n",
    "            \n",
    "        # For each comment build a dict to hold its features, indexed by comment id\n",
    "        ID = comment.id\n",
    "        comment_features[ID] = {}\n",
    "        for feat_name in api_feat:\n",
    "            comment_features[ID][feat_name] = comment.__dict__[api_feat[feat_name]]\n",
    "               \n",
    "        # Calculate age of comment (in minutes)\n",
    "        comment_dtime = datetime.datetime.fromtimestamp(comment.created_utc)\n",
    "        now_dtime = datetime.datetime.now()\n",
    "        comment_features[ID]['Age'] = (now_dtime - comment_dtime).total_seconds()/60\n",
    "        \n",
    "        # Calculate upvote rate (per minute)\n",
    "        comment_features[ID]['Upvote rate'] = comment_features[ID]['Upvotes']/comment_features[ID]['Age']\n",
    "\n",
    "    \n",
    "    \n",
    "    t_feat_2 = datetime.datetime.now()\n",
    "    t_feat = (t_feat_2 - t_feat_1).total_seconds()\n",
    "    \n",
    "    t_reply_1 = datetime.datetime.now()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate average number of 2nd-level replies for top comments:\n",
    "    #    (number of comments controlled by 'num_top_level' variable)\n",
    "    \n",
    "    #     First need to order the top-level comments by upvotes in order to grab the top ones\n",
    "    ups = [(ID, comment_features[ID]['Upvotes']) for ID in comment_features]\n",
    "    ups_by_comme = (pd.DataFrame(ups)\n",
    "                      .rename(columns = {0:'Comment ID', 1: 'Comment Ups'})\n",
    "                      .sort_values(by = 'Comment Ups', ascending = False)\n",
    "                      .iloc[:num_top_comments,:]\n",
    "                      .reset_index(drop = True)\n",
    "                   )\n",
    "    #     For each of the top-n comments now grab all replies and count them up \n",
    "    num_replies = [(comment.id, len(comment.replies.__dict__['_comments'])) \n",
    "                   for comment in subm.comments.__dict__['_comments'] \n",
    "                   if comment.id in ups_by_comme['Comment ID'].to_list()\n",
    "                  ]\n",
    "    num_replies = (pd.DataFrame(num_replies)\n",
    "                     .rename(columns = {0:'Comment ID', 1:'Num Replies'})    \n",
    "                  )\n",
    "    #     Merge these on the 'Comment ID' column\n",
    "    top_comment_performance = ups_by_comme.merge(num_replies, on = 'Comment ID')\n",
    "    \n",
    "    #     Calculate the number of upvotes per minute and replies per minute since the comment was created\n",
    "    top_comment_performance['Upvote rate'] = [top_comment_performance.loc[j, 'Comment Ups'] /\n",
    "                                              comment_features[top_comment_performance.loc[j, 'Comment ID']]['Age']\n",
    "                                              for j in top_comment_performance.index\n",
    "                                             ]\n",
    "    top_comment_performance['Reply rate'] = [top_comment_performance.loc[j, 'Num Replies'] /\n",
    "                                              comment_features[top_comment_performance.loc[j, 'Comment ID']]['Age']\n",
    "                                              for j in top_comment_performance.index\n",
    "                                             ]\n",
    "    #     Calculate average and standard deviation of the rates, append them to the feature dictionary\n",
    "    Avg_up_rate = top_comment_performance['Upvote rate'].mean()\n",
    "    Std_up_rate = top_comment_performance['Upvote rate'].std()\n",
    "    Avg_reply_rate = top_comment_performance['Reply rate'].mean()\n",
    "    Std_reply_rate = top_comment_performance['Reply rate'].std()\n",
    "    \n",
    "    \n",
    "    \n",
    "    t_reply_2 = datetime.datetime.now()\n",
    "    t_reply = (t_reply_2 - t_reply_1).total_seconds()\n",
    "    \n",
    "    \n",
    "    # There is an opportunity to create more features out of the comments. These could include:\n",
    "    #    explore the success of comments/replies made by the submitter of the original post\n",
    "    #    look at the distribution of comment upvotes (or of comment replies)\n",
    "    #    look at the average controversiality among comments or replies to comments\n",
    "    #    calculate the rate of gildings among comments and/or comment replies\n",
    "    \n",
    "    return Avg_up_rate, Std_up_rate, Avg_reply_rate, Std_reply_rate, t_feat, t_reply, t_del\n",
    "\n",
    "\n",
    "\n",
    "def submission_features(subm, num_top_comments = 5):\n",
    "    \n",
    "    # List of potentially informative features available from the API\n",
    "    #### (bring this outside the function so it doesn't get re-written thousands of times as I loop over submissions) ####\n",
    "    api_feat = {'Title': 'title',\n",
    "                'Author': 'author',\n",
    "                'ID': 'id',\n",
    "                'Gilded': 'gilded',\n",
    "                'Gildings': 'gildings',\n",
    "                'Upvotes': 'ups',\n",
    "                'Upvote ratio': 'upvote_ratio',\n",
    "                'Post time': 'created_utc',\n",
    "                'Views': 'view_count',\n",
    "                'Discussion type': 'discussion_type',\n",
    "                'Distinguished': 'distinguished',\n",
    "                'Contest mode': 'contest_mode',\n",
    "                'Content categories': 'content_categories',\n",
    "                'Edited': 'edited',\n",
    "                'Hidden': 'hidden',\n",
    "                'Crosspostable': 'is_crosspostable',\n",
    "                'Crossposts': 'num_crossposts',\n",
    "                'Meta': 'is_meta',\n",
    "                'OC': 'is_original_content',\n",
    "                'Reddit media': 'is_reddit_media_domain',\n",
    "                'Robot indexable': 'is_robot_indexable',\n",
    "                'Selfpost': 'is_self',\n",
    "                'Video': 'is_video',\n",
    "                'Likes': 'likes',\n",
    "                'Comments': 'num_comments',\n",
    "                'Adult content': 'over_18',\n",
    "                'Subreddit': 'subreddit',\n",
    "               }\n",
    "    \n",
    "    # Iterate through desired features to build a dictionary containing feature values for this submission\n",
    "    features = {}\n",
    "    for feat_name in api_feat:\n",
    "        features[feat_name] = subm.__dict__[api_feat[feat_name]]\n",
    "\n",
    "    # Extract author and subreddit names as strings\n",
    "    features['Author'] = features['Author'].name\n",
    "    features['Subreddit'] = features['Subreddit'].display_name\n",
    "    \n",
    "    # Convert UTC timestamp to time of day (in minutes since beginning of UTC day)\n",
    "    dtime_posted = datetime.datetime.fromtimestamp(features['Post time'])\n",
    "    features['Post time'] = dtime_posted.hour*60 + dtime_posted.minute\n",
    "    \n",
    "    # Calculate age of the post (in minutes)\n",
    "    features['Post age'] = (datetime.datetime.now() - dtime_posted).total_seconds()/60\n",
    "    \n",
    "    # Calculate upvotes per minute of age and comments per minute of age\n",
    "    features['Upvote rate'] = features['Upvotes']/features['Post age']\n",
    "    features['Comment rate'] = features['Comments']/features['Post age']\n",
    "    \n",
    "    # Extract and process comments\n",
    "    if subm.num_comments == 0:\n",
    "        Avg_up_rate, Std_up_rate, Avg_reply_rate, Std_reply_rate = (0, 0, 0, 0)\n",
    "    else:\n",
    "        Avg_up_rate, Std_up_rate, Avg_reply_rate, Std_reply_rate, t_feat, t_reply, t_del = get_toplevel_comment_info(subm, num_top_comments)\n",
    "    \n",
    "    features['Avg top comments up rate'] = Avg_up_rate\n",
    "    features['Std top comments up rate'] = Std_up_rate\n",
    "    features['Avg top comments reply rate'] = Avg_reply_rate\n",
    "    features['Std top comments reply rate'] = Std_reply_rate\n",
    "\n",
    "    \n",
    "    return features, t_feat, t_reply, t_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "Time spent processing comment features: 16.988363\n",
      "\n",
      "Time spent processing comment replies: 0.080727\n",
      "\n",
      "Time spent deleting more comments: 0.000000\n",
      "\n",
      "Total time spent on all submissions: 19.67003\n"
     ]
    }
   ],
   "source": [
    "all_submission_features = {}\n",
    "\n",
    "t_feat = 0\n",
    "t_reply = 0\n",
    "t_del = 0\n",
    "\n",
    "t_start = datetime.datetime.now()\n",
    "for j, subm in enumerate(multi_hot):\n",
    "    ID = subm.id\n",
    "    if j%10 == 0:\n",
    "        print(j)\n",
    "    all_submission_features[ID], t_feat_j, t_reply_j, t_del_j = submission_features(subm, 10)\n",
    "    \n",
    "    t_feat += t_feat_j\n",
    "    t_reply += t_reply_j\n",
    "    t_del += t_del_j\n",
    "    \n",
    "    if j == 10:\n",
    "        break\n",
    "t_end = datetime.datetime.now()\n",
    "\n",
    "        \n",
    "        \n",
    "print('Time spent processing comment features: {:.6f}\\n'.format(t_feat))\n",
    "print('Time spent processing comment replies: {:.6f}\\n'.format(t_reply))\n",
    "print('Time spent deleting more comments: {:.6f}\\n'.format(t_del))\n",
    "\n",
    "print('Total time spent on all submissions: {:.5f}'.format((t_end - t_start).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_submission_features).transpose()\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Submission(id='kahsgq')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gfao17x\n",
      "gfb6gil\n",
      "gfatx3e\n",
      "gfaq7iq\n",
      "gfb6fns\n",
      "gfareaw\n",
      "gfazj4a\n",
      "gfb6fyg\n",
      "gfbaens\n",
      "gfbhnz0\n",
      "gfayzqo\n",
      "gfbflhe\n",
      "gfb0o63\n",
      "gfb57zp\n",
      "gfbby0z\n",
      "gfan1g1\n",
      "gfbm3o6\n",
      "gfaxt2t\n",
      "gfaytu5\n",
      "gfbb0qe\n",
      "gfbd1tz\n",
      "gfbi6eb\n",
      "gfbin9k\n",
      "gfaw0zc\n",
      "gfb98wb\n",
      "gfb9ssw\n",
      "gfbdaeu\n",
      "gfbeurl\n",
      "gfbgm22\n",
      "gfbi92d\n",
      "gfbidr8\n",
      "gfbjb24\n",
      "gfbjeir\n",
      "gfbjwzp\n",
      "gfblm1k\n",
      "gfb978t\n",
      "gfap6eo\n",
      "gfawsou\n",
      "gfap4wj\n",
      "gfaqce1\n",
      "gfaxkez\n",
      "gfaynmz\n",
      "gfb44tq\n",
      "gfax88g\n",
      "gfaum06\n",
      "gfaoxg6\n",
      "gfb0wcz\n",
      "gfb13ai\n",
      "gfap3om\n",
      "gfazln9\n",
      "gfar1lv\n",
      "gfawute\n",
      "gfaybih\n",
      "gfazn9e\n",
      "gfbg6tb\n",
      "gfaraej\n",
      "gfazoc5\n",
      "gfazzvy\n",
      "gfb0028\n",
      "gfb0keq\n",
      "gfb1cic\n",
      "gfb1vks\n",
      "gfb1xrh\n",
      "gfb22kx\n",
      "gfb28kn\n",
      "gfb4624\n",
      "gfb5nak\n",
      "gfb61g7\n",
      "gfb6af8\n",
      "gfb6pfw\n",
      "gfb6rxn\n",
      "gfb7dte\n",
      "gfb7dup\n",
      "gfb89oh\n",
      "gfb8nu5\n",
      "gfb8xyx\n",
      "gfb9ipd\n",
      "gfb9r1u\n",
      "gfbabgd\n",
      "gfbbce1\n",
      "gfbbo55\n",
      "gfbe7m1\n",
      "gfbekgc\n",
      "gfb6dq7\n",
      "gfb6ndj\n",
      "gfb6ofk\n",
      "gfb7s5s\n",
      "gfb87cx\n",
      "gfb8dct\n",
      "gfb8dk4\n",
      "gfb9mm3\n",
      "gfbabbd\n",
      "gfbb1s3\n",
      "gfbc8fo\n",
      "gfbfg24\n",
      "gfbfhm8\n",
      "gfbfjkq\n",
      "gfbfk2j\n",
      "gfbfkar\n",
      "gfbhaq9\n",
      "gfaqcsq\n",
      "gfbaux3\n",
      "gfbboo6\n",
      "gfbbse5\n",
      "gfbcbgk\n",
      "gfbcq6l\n",
      "gfbcs6i\n",
      "gfbcvpj\n",
      "gfbcxd3\n",
      "gfbcxsm\n",
      "gfbczqq\n",
      "gfbd027\n",
      "gfbd1wv\n",
      "gfbd215\n",
      "gfbd49p\n",
      "gfbd9kx\n",
      "gfbd9vw\n",
      "gfbdd7x\n",
      "gfbdg7t\n",
      "gfbdhae\n",
      "gfbdilq\n",
      "gfbdl0u\n",
      "gfbdl8t\n",
      "gfbdodr\n",
      "gfbdx0c\n",
      "gfbdzew\n",
      "gfbdzk5\n",
      "gfbedf0\n",
      "gfbefbp\n",
      "gfber1k\n",
      "gfberb5\n",
      "gfbes4m\n",
      "gfbewc5\n",
      "gfbez8z\n",
      "gfbf3qt\n",
      "gfbf4dj\n",
      "gfbf6fd\n",
      "gfbf726\n",
      "gfbfael\n",
      "gfbfagc\n",
      "gfbfav7\n",
      "gfbfehg\n",
      "gfbfkq0\n",
      "gfbfkuq\n",
      "gfbfohd\n",
      "gfbfyxt\n",
      "gfbg4hx\n",
      "gfbg5g0\n",
      "gfbg5xi\n",
      "gfbg9wg\n",
      "gfbgble\n",
      "gfbgeab\n",
      "gfbgeg6\n",
      "gfbgfud\n",
      "gfbgfww\n",
      "gfbghl0\n",
      "gfbgkpk\n",
      "gfbglrj\n",
      "gfbgmil\n",
      "gfbgmrf\n",
      "gfbgmvu\n",
      "gfbgnan\n",
      "gfbgnf8\n",
      "gfbgofa\n",
      "gfbgoln\n",
      "gfbgt56\n",
      "gfbgwme\n",
      "gfbh17e\n",
      "gfbh28u\n",
      "gfbh3q0\n",
      "gfbh8a5\n",
      "gfbh8po\n",
      "gfbh9ox\n",
      "gfbh9yw\n",
      "gfbhe4g\n",
      "gfbhexs\n",
      "gfbhf11\n",
      "gfbhfez\n",
      "gfbhgf0\n",
      "gfbhhjz\n",
      "gfbhiz4\n",
      "gfbhjhs\n",
      "gfbhobw\n",
      "gfbhq5b\n",
      "gfbht6l\n",
      "gfbhuc8\n",
      "gfbhvpe\n",
      "gfbhwvq\n",
      "gfbhxg0\n",
      "gfbhxg8\n",
      "gfbi0wv\n",
      "gfbi1u8\n",
      "gfbi3is\n",
      "gfbi4lj\n",
      "gfbi4q7\n",
      "gfbi5fj\n",
      "gfbi8bp\n",
      "gfbicdr\n",
      "gfbijlx\n",
      "gfbmnrg\n",
      "gfbf5dr\n",
      "gfbi3q4\n",
      "gfbidvf\n",
      "gfbie74\n",
      "gfbiga4\n",
      "gfbigeu\n",
      "gfbigt4\n",
      "gfbii6y\n",
      "gfbijq5\n",
      "gfbikqi\n",
      "gfbin35\n",
      "gfbio58\n",
      "gfbipqr\n",
      "gfbiqaj\n",
      "gfbiw5a\n",
      "gfbixyb\n",
      "gfbj04y\n",
      "gfbj1nd\n",
      "gfbj34g\n",
      "gfbj8ni\n",
      "gfbjbem\n",
      "gfbjbtm\n",
      "gfbjduv\n",
      "gfbje4v\n",
      "gfbjjg8\n",
      "gfbjk7y\n",
      "gfbjkxn\n",
      "gfbjn2b\n",
      "gfbjp1j\n",
      "gfbjp2a\n",
      "gfbjq3b\n",
      "gfbjw63\n",
      "gfbjxhv\n",
      "gfbk252\n",
      "gfbk2ya\n",
      "gfbk5v3\n",
      "gfbkczw\n",
      "gfbkdw3\n",
      "gfbkffy\n",
      "gfbkh0q\n",
      "gfbki04\n",
      "gfbkk7k\n",
      "gfbko2c\n",
      "gfbkpu8\n",
      "gfbks8i\n",
      "gfbkuxx\n",
      "gfbkwbe\n",
      "gfbkwf6\n",
      "gfbkwrj\n",
      "gfbkxl4\n",
      "gfbl0fg\n",
      "gfbl0na\n",
      "gfbl2av\n",
      "gfbl53d\n",
      "gfbl5om\n",
      "gfbl62z\n",
      "gfbl6ju\n",
      "gfbl7q0\n",
      "gfbl812\n",
      "gfblahw\n",
      "gfblbgw\n",
      "gfbldms\n",
      "gfbldnt\n",
      "gfblj4a\n",
      "gfblj8i\n",
      "gfblj94\n",
      "gfblm65\n",
      "gfblmal\n",
      "gfblowy\n",
      "gfblp0p\n",
      "gfblpvc\n",
      "gfblqs0\n",
      "gfblqu4\n",
      "gfblyvd\n",
      "gfblyzp\n",
      "gfblzk5\n",
      "gfbm0z8\n",
      "gfbm3vv\n",
      "gfbm57h\n",
      "gfbm69z\n",
      "gfbm7fu\n",
      "gfbm7yg\n",
      "gfbmbk1\n",
      "gfbmc4q\n",
      "gfbmefh\n",
      "gfbmeu7\n",
      "gfbmfba\n",
      "gfbmfrw\n",
      "gfbmhyl\n",
      "gfbmiep\n",
      "gfbmjlq\n",
      "gfbmkf1\n",
      "gfbmnaz\n",
      "gfbmttb\n",
      "gfbmua6\n",
      "gfbmuqe\n",
      "gfbmusn\n",
      "gfbmw7x\n",
      "gfbmxpw\n",
      "gfbmxx5\n",
      "gfbmzpz\n",
      "gfbn0su\n",
      "gfbn5xr\n",
      "gfbn676\n",
      "gfbn7du\n",
      "gfbn7t7\n",
      "gfbna0w\n",
      "gfblxnj\n"
     ]
    }
   ],
   "source": [
    "for k in reddit.info(['t3_kahsgq', 't3_kaikjs']):\n",
    "    for comm in k.comments:\n",
    "        print(comm.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems like a good problem to have\n",
      "An animal on the plain woooooot\n"
     ]
    }
   ],
   "source": [
    "for k in reddit.info(['t1_gfaw0zc', 't1_gfaytu5']):\n",
    "    print(k.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Reddit",
   "language": "python",
   "name": "reddit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
